### 日志

一个名为“my_topic”的主题的一个日志由两个目录（名为`my_topic_0`和`my_topic_1`）组成的两个分区，这两个目录中有包含了这个主题的消息的数据文件。日志文件的格式是一系列的“日志条目”（“log entries”）；每个日志条目是一个4字节整数***N***存储消息长度和长度为***N***字节的消息。每条消息是通过一个64位的整数偏移来进行唯一识别的，这个偏移指明了（在这个分区上发送给这个主题的的所有消息的流中）这条消息的起始字节的位置。每条消息的在硬盘上格式会在后面描述。每个日志文件的名字都有它的第一条消息的偏移。所以创建的第一个文件是`00000000000.kafka`，并且其它每个文件会的整数名字都比前一个文件大***S***字节，其中***S***是配置中指定的最大日志文件大小。

记录的精确二进制格式是有版本的，并且作为一个标准接口进行维护，所以记录批次可以在生产者、代理和客户端之间进行传输，而不用进行重复复制或者转换。

把消息id作为消息偏移使用是不寻常的。最初的设想是使用生产者生产的GUID，并且在每个代理商维护一个GUID到偏移的映射。但是，因此，消费者必须为每个服务器维护一个ID，GUID的全局唯一性无法提供价值。另外，维护一个随机id和偏移映射的复杂性——需要一个必须与硬盘同步的重量级的索引结构，本质上需要一个完全持久化的随机访问数据结构。这样，为了简化查找结构，决定使用一个简单的每个分区的原子性的计数器，与分区id和节点id一起来唯一识别一条消息；这使得查找结构更简单，尽管可能有每个消费者请求的多次查找。但是，一旦采用了计数器，跳转到直接使用偏移量似乎是自然的——毕竟单调递增的整数对于一个分区来说是唯一的。

![img](/assets/kafka_log.png)

#### 1、写

日志允许总是在文件最后进行串行追加。当文件达到一个配置的大小（比如1GB）时，会转向新的文件。日志有两个配置参数：***M***，强制OS把文件刷到硬盘之前写的消息的条数，***S***，多少秒之后进行强刷。这提供了一个持久性的保证——当一个系统崩溃时最多丢失***M***条消息或者***S***秒的数据。

#### 2、读

通过指定一条消息的64位逻辑偏移和一个*S*字节的最大块大小进行读。会返回一个包含*S*字节缓存的消息的迭代器。*S*应该比任意一条消息都大，但是为了防止出现不正常的大消息，可以重试多次读，每次都使缓存大小加倍，直到读取成功。可以指定最大消息数量和最大缓存大小，让服务器拒绝超过指定量消息读取，并给客户端一个为了获取完整消息所需的读取的最大量的边界。读取缓存可能会包含不完整的消息，通过大小定界（size delimiting）可以很容易地检测到。

从一个偏移读的实际处理，首先要定位到数据保存的日志片段文件，根据全局偏移值来计算针对这个文件的偏移，然后从这个文件偏移开始读取。检索是通过对为每个文件维护的在内存中的范围进行一个简单的二分法查找变种（binary search variation）完成的。

日志提供了获取最近写入消息的能力，让客户端可以从“现在”开始订阅。这也对于消费者在授权期限内消费它的数据失败的场景有用。这种情况下，当客户端尝试消费一个不存在的偏移时，会得到一个`OutOfRangeException`，可以重置客户端或者对应于这种场景失败。

如下为发送给消费者的结果的格式。

```text
    MessageSetSend (fetch result)

    total length     : 4 bytes
    error code       : 2 bytes
    message 1        : x bytes
    ...
    message n        : x bytes
```

```text
    MultiMessageSetSend (multiFetch result)

    total length       : 4 bytes
    error code         : 2 bytes
    messageSetSend 1
    ...
    messageSetSend n
```

#### 3、删除

数据删除是一次一个日志片段地进行的。日志管理器使用两个指标（时间和大小）来区分哪些片段可以删除。对于基于时间的策略，会考虑记录的时间戳，使用片段文件中（与记录的顺序无关）最大的时间戳来定义整个片段的留存时间。默认情况下，基于大小的留存是未启用的。启用之后，当分区的整体大小超过配置的限制时，日志管理器会开始删除最老的日志片段。如果两种策略都开启，满足任意一个策略的日志片段都会被删除。为了避免锁读操作，同时允许删除操作修改片段列表的情况，使用了一种写时复制（copy-on-write）风格的片段列表实现，该实现能够提供一致性的视图，让进行删除的同时可以在一个日志片段的不可变得静态快照视图上进行二分法查找。

#### 4、保证

日志提供了一个参数***M***控制强刷到硬盘之前写入的消息的最大数量。启动时会运行一个日志恢复进程，遍历最新的日志片段中的所有消息，并验证每个消息条目是有效的。如果一个消息条目的大小和偏移的和小于文件的长度，并且消息荷载的CRC32与消息中保存的CRC匹配，那么这个消息条目是有效的。如果检测到损坏，日志会被截取到最后一个有效的偏移。

注意，有两种损坏必须要处理：未写入块由于崩溃而丢失的截断，和垃圾块被加到文件的损害。因为，一般OS不保证文件inode（索引节点，存储文件元信息的区域）和实际块数据之间的写顺序，所以除了丢失写入的数据，如果inode被更新而在包含写入数据的块被写入前发生了故障，文件中可能会被加入垃圾数据。CRC检测这种情况下，并防止它损坏日志（尽管，未写入的消息丢失了）。

