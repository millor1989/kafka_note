### 4.2、创建Kafka消费者

创建`KafkaConsumer`对象需要三个必要属性`bootstrap.servers`、`key.deserializer` 和 `value.deserializer`。

- `bootstrap.servers` 属性指定了 Kafka 集群的连接字符串。

- `key.deserializer` 和 `value.deserializer` 属性指定将字节数组转化为 Java 对象使用的类。

- `group.id` 属性不是必需的，他指定 `KafkaConsumer` 属于哪一个消费者群组。也可以创建不属于任何消费者群组的消费者。

代码示例：

```java
    Properties props = new Properties();
    props.put("bootstrap.servers", "broker1:9092,broker2:9092");
    props.put("group.id", "CountryCounter");
    props.put("key.deserializer",
      "org.apache.kafka.common.serialization.StringDeserializer");
    props.put("value.deserializer",
      "org.apache.kafka.common.serialization.StringDeserializer");

    KafkaConsumer<String, String> consumer = new KafkaConsumer<String,
    String>(props);
```

这里假设消息的键和值都是字符串类型，所以使用了内置的`StringDeserializer`，并使用字符串类型创建了 `KafkaConsumer` 对象。

### 4.3、订阅主题

使用`subscribe()`方法接收一个主题列表作为参数，来订阅主题：

```java
	consumer.subscribe(Collections.singletonList("customerCountries")); // ➊
```

➊ 为了简单起见，创建了一个只包含单个元素的列表，主题的名字叫作「customer Countries」。

也可以在调用 subscribe() 方法时传入一个正则表达式。正则表达式可以匹配多个主题，如果创建了新的主题，并且主题的名字与正则表达式匹配，那么会立即触发一次再均衡，消费者就可以读取新添加的主题。如果应用程序需要读取多个主题，并且可以处理不同类型的数据，那么这种订阅方式就很管用。在 Kafka 和其他系统之间复制数据时，使用正则表达式的方式订阅多个主题是很常见的做法。

比如，订阅与`test`相关的主题：

```java
	consumer.subscribe("test.*")
```

### 4.4、轮询

消息轮询是消费者 API 的核心，消费者订阅了主题，轮询则处理所有的细节，包括群组协调、分区再均衡、发送心跳和获取数据。开发者只用使用一组简单的 API 来处理从分区返回的数据。消费者代码主要部分示例：

```java
try {
  while (true) { //➊
      ConsumerRecords<String, String> records = consumer.poll(100); //➋
      for (ConsumerRecord<String, String> record : records) //➌
      {
          log.debug("topic = %s, partition = %s, offset = %d, customer = %s,
             country = %s\n",
             record.topic(), record.partition(), record.offset(),
             record.key(), record.value());

          int updatedCount = 1;
          if (custCountryMap.countainsValue(record.value())) {
              updatedCount = custCountryMap.get(record.value()) + 1;
          }
          custCountryMap.put(record.value(), updatedCount)

          JSONObject json = new JSONObject(custCountryMap);
          System.out.println(json.toString(4)) //➍
      }
  }
} finally {
  consumer.close(); //➎
}
```

➊无限循环，消费者实际上是一个长期运行的应用程序，它通过持续轮询向 Kafka 请求数据。

❷ 执行`poll()`是关键。消费者必须持续对 Kafka 进行轮询，否则会被认为已经死亡，它的分区会被移交给群组里的其他消费者。传给 poll() 方法的参数是一个超时时间，用于控制 poll() 方法的阻塞时间（在消费者的缓冲区里没有可用数据时会发生阻塞）。如果该参数被设为 0，poll() 会立即返回，否则它会在指定的毫秒数内一直等待 broker 返回数据。

❸ `poll()` 方法返回一个记录列表。每条记录都包含了记录所属主题的信息、记录所在分区的信息、记录在分区里的偏移量，以及记录的键值对。一般会遍历这个列表，逐条处理这些记录。`poll()` 方法有一个超时参数，它指定了方法在多久之后可以返回，不管有没有可用的数据都要返回。超时时间的设置取决于应用程序对响应速度的要求，比如要在多长时间内把控制权归还给执行轮询的线程。

❹ 把结果保存起来或者对已有的记录进行更新，处理过程也随之结束。这里的目的是统计来自各个地方的客户数量，所以使用了一个散列表来保存结果，并以 JSON 的格式打印结果。

❺ 在退出应用程序之前使用 `close()` 方法关闭消费者。网络连接和 socket 也会随之关闭，并立即触发一次再均衡，而不是等待群组协调器发现它不再发送心跳并认定它已死亡，因为那样需要更长的时间，导致整个群组在一段时间内无法读取消息。

轮询不只是获取数据那么简单。在第一次调用新消费者的 `poll()` 方法时，它会负责查找 `GroupCoordinator`，然后加入群组，接受分配的分区。如果发生了再均衡，整个过程也是在轮询期间进行的。当然，心跳也是从轮询里发送出去的。所以，要确保在轮询期间所做的任何处理工作都应该尽快完成。

###### 线程安全

在同一个群组里，无法让一个线程运行多个消费者，也无法让多个线程安全地共享一个消费者。按照规则，一个消费者使用一个线程。如果要在同一个消费者群组里运行多个消费者，需要让每个消费者运行在自己的线程里。最好是把消费者的逻辑封装在自己的对象里，然后使用 Java 的 `ExecutorService` 启动多个线程，使每个消费者运行在自己的线程中。

### 4.5、消费者的配置

Kafka 消费者配置参数大多都有合理的默认值，一般不需修改，但某些参数与消费者性能和可用性关系很大。

#### 4.5.1、fetch.min.bytes

该属性指定了消费者从服务器获取记录的最小字节数。broker 在收到消费者的数据请求时，如果可用的数据量小于 `fetch.min.bytes` 指定的大小，那么它会等到有足够的可用数据时才把它返回给消费者。这样可以降低消费者和 broker 的工作负载，因为在主题不是很活跃的时候（或者一天里的低谷时段）就不需要来来回回地处理消息。如果没有很多可用数据，但消费者的 CPU 使用率却很高，那么就需要把该属性的值设得比默认值大。如果消费者的数量比较多，把该属性的值设置得大一点可以降低 broker 的工作负载。

#### 4.5.2、fetch.max.wait.ms

通过 `fetch.min.bytes` 告诉 Kafka，等到有足够的数据时才把它返回给消费者。而 `feth.max.wait.ms` 则用于指定 broker 的等待时间，默认是 500ms。如果没有足够的数据流入 Kafka，消费者获取最小数据量的要求就得不到满足，最终导致 500ms 的延迟。如果要降低潜在的延迟（为了满足 SLA），可以把该参数值设置得小一些。如果 `fetch.max.wait.ms` 被设为 100ms，并且 `fetch.min.bytes` 被设为 1MB，那么 Kafka 在收到消费者的请求后，要么返回 1MB 数据，要么在 100ms 后返回所有可用的数据，就看哪个条件先得到满足。

#### 4.5.3、max.partition.fetch.bytes

该属性指定了服务器从每个分区里返回给消费者的最大字节数。它的默认值是 1MB，也就是说，`KafkaConsumer.poll()` 方法从每个分区里返回的记录最多不超过 `max.partition.fetch.bytes` 指定的字节。如果一个主题有 20 个分区和 5 个消费者，那么每个消费者需要至少 4MB 的可用内存来接收记录。在为消费者分配内存时，可以给它们多分配一些，因为如果群组里有消费者发生崩溃，剩下的消费者需要处理更多的分区。`max.partition.fetch.bytes` 的值必须比 broker 能够接收的最大消息的字节数（通过 `max.message.size` 属性配置）大，否则消费者可能无法读取这些消息，导致消费者一直挂起重试。在设置该属性时，另一个需要考虑的因素是消费者处理数据的时间。消费者需要频繁调用 `poll()` 方法来避免会话过期和发生分区再均衡，如果单次调用 `poll()` 返回的数据太多，消费者需要更多的时间来处理，可能无法及时进行下一个轮询来避免会话过期。如果出现这种情况，可以把 `max.partition.fetch.bytes` 值改小，或者延长会话过期时间。

#### 4.5.4、session.timeout.ms

该属性指定了消费者在被认为死亡之前可以与服务器断开连接的时间，默认是 3s。如果消费者没有在 `session.timeout.ms` 指定的时间内发送心跳给群组协调器，就被认为已经死亡，协调器就会触发再均衡，把它的分区分配给群组里的其他消费者。该属性与 `heartbeat.interval.ms` 紧密相关。`heartbeat.interval.ms` 指定了 `poll()` 方法向协调器发送心跳的频率，`session.timeout.ms` 则指定了消费者可以多久不发送心跳。所以，一般需要同时修改这两个属性，`heartbeat.interval.ms` 必须比 `session.timeout.ms` 小，一般是 `session.timeout.ms` 的三分之一。如果 `session.timeout.ms` 是 3s，那么 `heartbeat.interval.ms` 应该是 1s。把 `session.timeout.ms` 值设得比默认值小，可以更快地检测和恢复崩溃的节点，不过长时间的轮询或垃圾收集可能导致非预期的再均衡。把该属性的值设置得大一些，可以减少意外的再均衡，不过检测节点崩溃需要更长的时间。

#### 4.5.5、auto.offset.reset

该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长时间失效，包含偏移量的记录已经过时并被删除）该作何处理。它的默认值是 `latest`，意思是说，在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）。另一个值是 `earliest`，意思是说，在偏移量无效的情况下，消费者将从起始位置读取分区的记录。

#### 4.5.6、enable.auto.commit

提交偏移量的方式有很多种。该属性指定了消费者是否自动提交偏移量，默认值是 `true`。为了尽量避免出现重复数据和数据丢失，可以把它设为 `false`，由自己控制何时提交偏移量。如果把它设为 true，还可以通过配置 `auto.commit.interval.ms` 属性来控制提交的频率。

#### 4.5.7、partition.assignment.strategy

分区会被分配给群组里的消费者。`PartitionAssignor` 根据给定的消费者和主题，决定哪些分区应该被分配给哪个消费者。Kafka 有两个默认的分配策略。

##### 　　Range

　　该策略会把主题的若干个连续的分区分配给消费者。假设消费者 C1 和消费者 C2 同时订阅了主题 T1 和主题 T2，并且每个主题有 3 个分区。那么消费者 C1 有可能分配到这两个主题的分区 0 和分区 1，而消费者 C2 分配到这两个主题的分区 2。因为每个主题拥有奇数个分区，而分配是在主题内独立完成的，第一个消费者最后分配到比第二个消费者更多的分区。只要使用了 Range 策略，而且分区数量无法被消费者数量整除，就会出现这种情况。

##### 　　RoundRobin

　　该策略把主题的所有分区逐个分配给消费者。如果使用 RoundRobin 策略来给消费者 C1 和消费者 C2 分配分区，那么消费者 C1 将分到主题 T1 的分区 0 和分区 2 以及主题 T2 的分区 1，消费者 C2 将分配到主题 T1 的分区 1 以及主题 T2 的分区 0 和分区 2。一般来说，如果所有消费者都订阅相同的主题（这种情况很常见），RoundRobin 策略会给所有消费者分配相同数量的分区（或最多就差一个分区）。

可以通过设置 `partition.assignment.strategy` 来选择分区策略。默认使用的是 `org.apache.kafka.clients.consumer.RangeAssignor`，这个类实现了 Range 策略，不过也可以把它改成 `org.apache.kafka.clients.consumer.RoundRobinAssignor`。还可以使用自定义策略，在这种情况下，`partition.assignment.strategy` 属性的值就是自定义类的名字。

#### 4.5.8、client.id

该属性可以是任意字符串，broker 用它来标识从客户端发送过来的消息，通常被用在日志、度量指标和配额里。

#### 4.5.9、max.poll.records

该属性用于控制单次调用 `call()` 方法能够返回的记录数量，可以控制在轮询里需要处理的数据量。

#### 4.5.10、receive.buffer.bytes 和 send.buffer.bytes

socket 在读写数据时用到的 TCP 缓冲区也可以设置大小。如果它们被设为 -1，就使用操作系统的默认值。如果生产者或消费者与 broker 处于不同的数据中心内，可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽。