### 使用场景

#### 消息（Messaging）

Kafka可以很好地作为传统消息代理的替代。消息代理的用途很多（从数据的生产者解耦处理过程，缓存未处理的消息，等等）。与大多数的消息系统相比，Kafka有更好的吞吐量、内置分区、备份、并且容错，这使得Kafka成为大规模消息处理应用的好的解决方案。

根据经验，消息的使用通常相对地低吞吐量，但是可能需要较低的端到端延时，并且经常依赖Kafka提供的强大的持久性保证。

在这个领域Kafka是可以与传统的消息系统（比如，ActiveMQ或RabbitMQ）进行对比的。

#### 网站活动追踪

Kafka的最初应用场景是，重建一个用户活动跟踪管道，作为一个实时的发布订阅馈送（feeds）集合。这意味着网站活动（页面浏览、搜索、或者用户采取的其他行为）会被以每个活动类型一个主题进行发布。这些馈送可以用于订阅，进而被用于多种使用场景，包括实时处理、实时监控、和加载到Hadoop或者离线数据仓库系统进行离线的处理和报告。

活动追踪通常是高数据量的，因为每个用户的页面浏览都会产生许多的活动信息。

#### 指标（Metrics）

Kafka经常被用于操作上的监控数据。这涉及到了从分布式应用聚合数据以产生操作数据的中心化馈送。

#### 日志聚合

许多人把Kafka作为日志聚合解决方案的替代。一般，日志聚合从服务器收集物理日志文件并把这些文件放到一个中央位置（一个文件服务器或者HDFS）进行处理。Kafka抽离了文件明细，并且提供了把日志或者事件数据作为消息流的一个更简洁的抽象。这能够使处理延时更低，并且对多数据源的支持和分布式数据的消费更简单。与日志中心系统比如Scribe 或者Flume相比，Kafka提供了等价的高性能，由于备份提供了更强的持久性保证，并且端到端延时更低。

#### 流处理

许多Kafka用户处理由多个阶段组成的处理管道中的数据，其中原始输入数据消费自Kafka主题，然后进行聚合、丰富（enriched）、或者转换到新的主题进行进一步的消费或者随后的处理。比如，推荐新闻文章的处理管道，可以从RSS馈送爬取文章内容并将其发布到一个“article”主题；进一步的处理可以规范或者去重这个内容并将清洗后的文章内容发布到一个新的主题；最终的处理阶段可以是尝试向用户推荐这个内容。这种处理管道基于单个的主题创建了实时数据流的图。从0.10.0.0开始，Apache Kafka包含了一个轻量级的流处理库Kafka Streams来执行上面描述的数据处理。除了Kafka Streams，可选的开源流处理工具包括Apache Storm和Apache Samza。

#### 事件采集（Event Sourcing）

事件采集是一种应用设计风格，把状态变化以时序记录的形式进行记录。Kafka支持超大规模的日志数据，使它成为这种风格构建的应用的一个优秀的后端支撑。

#### Commit Log

Kafka可以用作分布式系统的一个外部commit-log。这个log帮助备份节点间的数据，并且可以被故障节点作为重新同步机制来恢复它们的数据。Kafka的日志压缩（compaction）特性帮助支持了这种应用场景。在这种应用场景下，Kafka类似于Apache BookKeeper项目。