### 消息发送语义

消息发送语义包括：

- 最多一次——消息可能丢失，但不会重复发送
- 至少一次——消息从不丢失，但可能重复发送
- 仅仅一次——消息仅仅发送一次

值得注意的是，可以把这个问题分为两个问题：发布消息的持久性保证和消费消息时的保证

许多系统声明提供“仅仅一次”的发送语义，但是很有必要阅读细则（fine print），大多数声明是误导性的（例如，不解释消费者或者生产者故障的情况，多个消费者的情况，写到硬盘的数据可能丢失的情况）。

Kafka的语义很直接。当发布消息的时候，有一个消息被“committed”到日志的概念。一旦发布的消息被committed，只要备份这个消息写到的分区的一个代理活跃，它将不会丢失。

如果生产者尝试发布一条消息，但是发生了网络错误，它将不能确定这个错误发生在消息被committed之前还是之后。这与用自动生成的主键往数据库表中插入数据的语义类似。在0.11.0.0之前，如果生产者接收表示消息被committed的响应失败，它没有重发消息之外的选择。这提供的是“至少一次”的语义，因为，如果初次请求事实上是成功的，在重发过程中这条消息可能会被再次写入日志。从0.11.0.0开始，Kafka生产者也支持一个幂等的发送选项，可以保证重发消息不会再日志中产生重复的记录。为了达到这个目的，代理为每个生产者分配一个ID，并且用生产者与每个消息一起发送的一个序号来去重消息。

也是从0.11.0.0开始，生产者支持用事务类似的语义（即，所有消息的写入要么都成功要么都失败）发送消息到多个主题分区。这个的主要使用场景是Kafka主题直间的仅仅一次的处理。并不是所有的使用场景都需要这么强的保证。对于延时敏感的应用场景，允许生产者指定希望使用的持久性级别。如果生产者指定要等待消息被committed，则可能需要10ms的时间。但是，生产者也可以指定执行完全异步地发送，或者只用等待leader有了这条消息。

对于消费者，对于相同的偏移，所有的副本都有相同的日志。消费者控制它在日志中的位置。如果消费者从不崩溃，它可以把这个位置保存在内存中，但是如果消费故障，而希望用另一个进程接管这个主题分区，新的进程就需要选择一个合适的位置开始进行处理。假如消费者读取一些消息——它有几个处理这些消息并更新它的位置的选项：

1. 读取消息，在日志中保存它的位置，最后处理消息。如果，消费者进程在保存它的位置后，但是保存它消息处理的结果前故障。接管处理的进程可以从保存的位置开始处理，即使这个位置之前的一些消息没有被处理过。这对应于“至多一次”语义，因为这种情况下一些消息不会被处理。
2. 读取消息，处理消息，最后保存它的位置。如果消费者进程在处理消息后但是保存它的位置之前故障。接管处理进程处理的前几条消息可能已经被处理过。这对应于消费者故障情况的“至少一次”语义。在徐国情况下，消息有一个主键，所以更新是幂等的（接受相同消息两次，只用它本身的拷贝覆盖一条记录）。

但是仅仅一次的语义呢？当从一个Kafka主题消费并往另一个主题生产（与Kafka Streams应用一样），可以利用之前提到的新的事务性生产者功能。消费者位置保存为一个主题中的一条消息，所以，可以在与输出主题接收处理后数据的相同的事务中，把偏移写到Kafka。如果事务被抛弃，消费者位置会返回旧的值，并且输出主题上生成的数据对其它消费者是不可见的，这要视它们的“独立级别”（“isolation level”）而定。在默认的“read_uncommitted”独立级别中，所有的消息对消费者都是可见的，即使它们是被抛弃的事务的一部分，但是在“read_committed”独立级别中，消费者只会返回committed的事务的消息（和不是事务一部分的消息）。

当写到外部系统时，限制在于需要协调消费者的位置和它实际作为输出保存的数据。经典的方式是，引入消费者位置存储和消费者输出存储两阶段的提交。但是可以通过让消费者把它的偏移保存在它的输出位置，从而使处理变得更简单和一般。这样更好，因为消费者要写到的许多输出系统可能不支持两阶段的提交。一个例子是，Kafka Connect连接器把数据和它读取的数据的偏移写入到HDFS，以便保证数据和偏移都被更新或者都不被更新。

Kafka在Kafka Streams中支持仅仅一次的发送，当在Kafka主题之间进行数据传输和处理时，可以用事务性的生产者/消费者来提供仅仅一次的发送。对于其它系统的仅仅一次的发送需要与这些系统协调，但是Kafka提供了偏移，使得这种实现变得可行。另外，Kafka默认保证至少一次的发送，并且，通过禁止生产者重试并在消费者处理一批消息之前保存偏移可以实现至多一次。