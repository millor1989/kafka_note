### 效率

Kafka的一个主要应用场景是处理网页活动数据，数据量比较大：每个页面浏览可能产生数十次写操作。另外，假设发布的每个消息被至少一个（通常很多）消费者读取，因此要尽量使消费低开销。

根据经验，构建和运行几个相似的系统，效率是高效多租户操作的关键。如果下游基础设施服务容易因为应用使用中的小问题变为瓶颈，这些小的改变通常会造成麻烦。如果速度非常快，就可以确保应用在基础设施之前消除了高负载。在一个中心化的集群上，当尝试运行一个中心化的服务用以支持数十个或数百个应用时，这是尤其重要的，因为使用模式的改变几乎每天都会发生。

上一节持久化，讨论了硬盘的效率。解决了低效硬盘访问模式之后，剩下两个这种系统中常见的低效原因：**太多的小I/O操作**和**过多的字节复制**。

小I/O的问题，在客户端和服务端之间会发生，在服务端自己的持久化操作中也会发生。

为了避免这个问题，Kafka的协议围绕**“消息集合”（message set）**的抽象构建，很自然地将消息分组。这可以让网络一起请求网络分组，并且缓冲了网络往返的开销，而不是每次发送一个请求。反过来。服务端一次性的把大块的消息追加到它的日志，消费者一次性的获取大的线性块。

这种简单地优化可以产生呈数量级的提速。批处理导致了更大的网络包、更大的顺序硬盘操作、持续的内存块，等等，所有这些使得Kafka将突发的随即消息写操作转换为流向消费者的线性写操作。

另一个低效问题是字节复制。在低消息频率时这不是问题，但是高负载情况下影响是显著的。为了避免这个问题，Kafka才用了一种**标准化的二进制消息格式**，这种格式是与生产者、代理、消费者共享的（数据块可以不用进行修改就在它们之间传输）。

代理维护的消息日志只是一个文件的目录，每个都配备了一系列的消息集合，这些消息集合已经以生产者和消费者使用的相同的格式被写入到硬盘。维持这种通用的格式可以允许对最重要的操作——持久化日志块的网络传输——进行优化。如今的unix操作系统提供了一种高度优化的传输pagecache数据到socket的代码路径；在Linux中这是用**sendfile** system call实现的。

要理解sendfile的影响，需要理解从文件传输数据到socket的一般路径：

1. 操作系统从硬盘读取数据到kernel空间中的pagecache。
2. 应用从kernel空间读取数据到用户空间缓冲。
3. 应用把数据写回到kernel空间的socket缓冲。
4. 操作系统从socket缓冲复制数据到NIC缓冲，在NIC缓冲中数据被通过网络进行发送。

很明显这是低效的，有四次的复制和两次的系统调用。使用sendfile可以让OS直接从pagecache发送数据到网络，从而避免了反复的复制。所以，在这种优化过的路径中，只需要最后的到NIC缓冲的复制。

使用上面的零复制优化，数据只会仅仅一次被复制到pagecache，并且每次消费都重用，而不是保存在内存中每次读取的时候都复制到用户空间。这可以使消息以接近网络连接限制的速率被消费。

**pagecache和sendfile**的组合意味着，在Kafka集群上消费者几乎总是可以被满足，并且看不到任何硬盘读取活动，数据全部都是通过缓存提供的。

#### 1、端到端的批压缩

某些情况下，瓶颈实际上不是CPU或者硬盘而是网络带宽。对于需要在数据中心间通过广域网发送消息的数据管道尤其如此。用户可以在不需要Kafka支持的情况下每发送一条消息压缩一次，但是这会导致压缩比率低的问题，因为同类消息会有冗余（比如，JSON中的属性名，或者web日志中的用户agent，或者一般的字符串值）。高效的压缩需要一起压缩多条消息，而不是单独地压缩一条消息。

Kafka支持批压缩，并有一个高效的批压缩格式。一批消息可以被集合到一起进行压缩并以这种格式发送到服务器。这个批次的消息会被以压缩的格式写并且在日志中也是压缩的，并且只会被消费者解压缩。

Kafka支持GZIP、Snappy、LZ4和ZStandard压缩协议。

