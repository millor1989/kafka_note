设计Kafka是为了能够使它充当一个处理大型公司的所有实时数据馈送的统一平台。为了实现这个目标，考虑了相当广泛的使用场景。

它必须具有很高的吞吐量以支持大量的事件流，比如实时日志聚合。

它需要能够优雅的处理大量数据的积压（backlogs），以能够支持从离线系统周期性的加载数据。

它也意味着这个系统要有很低的传输延时，以应对传统的消息应用场景。

想要支持分区、分布式、实时的处理这些事件馈送，以能够创建新的、派生的馈送。这催生了Kafka的分区和消费模型。

最后，为了保证馈送流到其它数据系统进行服务，Kafka必须在机器故障时能够保证容错。

支持这些应用导致Kafka被设计为一个具有许多独特组件的系统，与传统的消息系统相比，Kafka更加类似于一个数据库日志。

